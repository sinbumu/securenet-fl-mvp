### 예상 질문 및 답변 (Q&A)

#### Q1: 이 프로젝트에서 마주한 가장 큰 기술적 난관은 무엇이었고, 어떻게 해결했나요?

- **A1: XGBoost 모델과 표준 연합학습(FedAvg)의 근본적인 비호환성 문제였습니다.**
    - **난관 상세**: 각 클라이언트(은행)의 데이터 분포가 다르면, 학습되는 XGBoost 모델의 트리 구조와 파라미터 수가 완전히 달라집니다. 하지만 FedAvg 알고리즘은 모든 모델의 구조가 동일하다고 가정하고 파라미터를 평균 내기 때문에, 이종(heterogeneous) 트리 모델을 집계하는 과정에서 `ValueError`가 발생했습니다.
    - **해결 과정**:
        1.  **초기 시도**: 하이퍼파라미터를 강제로 통일하여 모델 구조를 맞추려 했으나, 데이터 특성에 따라 동적으로 결정되는 파라미터(`scale_pos_weight` 등) 때문에 근본적인 해결책이 되지 못했습니다.
        2.  **전략 변경 (MVP를 위한 현실적 대안)**: 안정적인 MVP 완성을 위해, 표준 FedAvg을 포기하고 **'순차적 학습(Sequential Learning)'** 방식으로 전략을 수정했습니다. 첫 번째 클라이언트의 모델을 받아 다음 클라이언트의 초기 모델로 전달하며 순차적으로 학습을 진행하는 방식입니다. 이는 엄밀한 의미의 동시 학습은 아니지만, 각 클라이언트의 데이터 특성을 순서대로 반영할 수 있는 현실적인 대안이었습니다.
        3.  **장기적 비전 수립**: 이 경험을 통해, XGBoost와 같은 트리 기반 모델의 연합학습에는 파라미터가 아닌 그래디언트와 헤시안을 주고받는 **'그래디언트 기반 연합 부스팅(Gradient-based Federated Boosting)'** 방식이 필수적임을 깨달았습니다. 이 내용은 `ai/README.md`에 기술 로드맵으로 정리하여 향후 프로젝트의 발전 방향으로 제시했습니다.

---

#### Q2: 연합학습 환경에서 데이터 보안과 프라이버시는 어떻게 보장하나요? 우리 시스템은 어떤 수준의 보안을 제공하며, 향후 어떻게 강화할 수 있나요?

- **A2: 현재는 연합학습의 기본 모델을 통해, 향후에는 암호화 및 노이즈 추가 기술로 강화할 수 있습니다.**
    - **기본 보안 (현재 수준)**: 원시 데이터(raw data)가 각 기관의 로컬 환경을 절대 벗어나지 않고, 오직 학습된 모델 파라미터만 중앙 서버와 교환됩니다. 이것만으로도 데이터 유출의 핵심 위험을 원천적으로 차단합니다.
    - **잠재적 위협 및 한계**:
        - **모델 역공학 (Model Inversion Attack)**: 악의적인 서버가 전송된 모델 업데이트를 분석하여 원본 학습 데이터의 통계적 정보나 특정 샘플을 추론할 이론적 가능성이 존재합니다.
        - **멤버십 추론 공격 (Membership Inference Attack)**: 특정 데이터가 모델 학습에 사용되었는지 여부를 알아내려는 공격입니다.
    - **향후 보안 강화 방안**:
        1.  **보안 집계 (Secure Aggregation)**: 중앙 서버조차 개별 클라이언트의 모델을 볼 수 없도록 암호화된 상태에서 집계를 수행하는 기술입니다. 각 클라이언트가 모델 업데이트에 마스킹 값을 더해 전송하면, 서버는 모든 값을 합산합니다. 이 과정에서 마스킹 값들이 서로 상쇄되어 최종적으로 안전하게 집계된 모델만 남게 됩니다.
        2.  **차분 프라이버시 (Differential Privacy)**: 모델 파라미터에 의도적인 노이즈를 추가하여, 특정 데이터 샘플 하나가 모델에 미치는 영향을 통계적으로 거의 구별할 수 없게 만드는 강력한 프라이버시 보존 기술입니다. 멤버십 추론 공격 등을 효과적으로 방어할 수 있습니다.

---

#### Q3: 현재 시스템의 한계는 무엇이며, 어떤 기술을 통해 극복할 수 있을까요?

- **A3: 현재는 정적/순차적 학습에 머물러 있지만, 그래디언트 부스팅과 GNN을 통해 동적/고도화된 시스템으로 발전시킬 수 있습니다.**
    - **현재 시스템의 한계**:
        1.  **모델 집계의 한계**: 현재의 순차 학습 방식은 동시 학습이 아니며, 클라이언트의 학습 순서에 결과가 편향될 수 있습니다.
        2.  **정적 연합학습**: 사전에 정의된 클라이언트만 참여하는 정적인(static) 환경으로, 새로운 유형의 공격에 실시간 대응이 어렵습니다.
        3.  **피드백 부재**: 모델이 실제 운영 환경에서 내린 예측의 결과(정탐/오탐)가 다시 학습에 반영되는 피드백 루프가 없습니다.
    - **극복 및 고도화 방안**:
        1.  **그래디언트 기반 연합 부스팅 (Gradient-based Federated Boosting)**: XGBoost 연합학습의 근본적인 해결책입니다. 클라이언트들은 모델 파라미터 대신, 각자의 데이터로 계산한 그래디언트와 헤시안 통계량을 서버와 공유합니다. 서버는 이를 취합해 글로벌 트리를 한 단계씩 성장시키므로, 이종 데이터 환경에서도 일관된 고성능 모델을 만들 수 있습니다.
        2.  **온라인 피드백 + 그래프 신경망 (Online Feedback + GNN)**: 실시간으로 발생하는 금융 거래와 사기 탐지 결과를 지속적으로 학습에 반영하는 '온라인 학습'을 도입하고, 여러 금융 기관과 사용자 간의 복잡한 거래 관계를 '그래프'로 모델링하여 GNN으로 분석할 수 있습니다. 이는 개별 거래만 보는 것을 넘어, 사기 집단과 같은 복잡한 네트워크 패턴을 탐지하는 데 매우 효과적입니다. 이를 통해 시스템을 정적인 분석 도구가 아닌, **지속적으로 진화하는 동적인 방어 시스템**으로 발전시킬 수 있습니다.

---
### 핵심 기술 상세 설명

#### 1. 보안 집계 (Secure Aggregation)

- **개념**: 중앙 서버가 개별 클라이언트의 모델 업데이트(파라미터, 그래디언트 등)를 전혀 보지 못하면서도, 전체 클라이언트 업데이트의 총합(또는 평균)은 정확하게 계산할 수 있도록 하는 암호화 프로토콜입니다. "누가 어떤 값을 냈는지 모르지만, 그 총합은 알 수 있는" 기술입니다.
- **작동 방식**: 각 클라이언트는 자신의 모델 업데이트에 무작위로 생성된 마스킹 값(노이즈)을 더해 서버에 전송합니다. 이 마스킹 값들은 모든 클라이언트에 걸쳐 합산했을 때 정확히 0이 되도록 교묘하게 설계됩니다. 따라서 서버는 마스킹 된 값들을 모두 더함으로써, 노이즈는 상쇄시키고 순수한 업데이트의 총합만을 얻게 됩니다.
- **Flower와의 관계**: Flower는 `Strategy` 맞춤 설정을 통해 보안 집계를 구현할 수 있는 유연한 구조를 제공합니다. Flower 자체에서 직접적인 프로토콜을 제공하기보다는, 사용자가 동형 암호(Homomorphic Encryption) 라이브러리나 보안 다자 계산(Secure MPC) 프로토콜을 통합하여 보안 집계 로직을 `Strategy`에 구현할 수 있습니다.
- **XGBoost와의 관계**: FedAvg 방식의 연합학습에서 XGBoost 모델 파라미터를 집계할 때 적용 가능합니다. 하지만 더 큰 시너지는 아래에 설명될 **SecureBoost**에서 나타납니다. SecureBoost는 암호화된 그래디언트 통계량을 교환하는데, 이 교환 및 집계 과정의 보안을 위해 보안 집계 기술이 핵심적으로 사용됩니다.

#### 2. 차분 프라이버시 (Differential Privacy)

- **개념**: 알고리즘의 출력 결과로부터 특정 개인의 정보가 데이터셋에 포함되었는지 여부를 추론하기 어렵게 만드는, 수학적으로 정의된 강력한 프라이버시 보장 기술입니다. 모델 역공학이나 멤버십 추론 공격에 대한 방어책으로 사용됩니다.
- **작동 방식**: 모델 업데이트(파라미터, 그래디언트 등)를 서버에 전송하기 전에, 통계적으로 잘 정의된 노이즈(예: 라플라스 또는 가우시안 노이즈)를 의도적으로 추가합니다. 이 노이즈는 개별 데이터 포인트가 모델에 미치는 영향을 희석시켜, 특정 개인의 기여분을 식별 불가능하게 만듭니다. 프라이버시 보호 수준과 모델 정확도 사이에는 트레이드오프 관계가 존재합니다.
- **Flower와의 관계**: Flower 클라이언트 단에서 모델 파라미터를 전송하기 직전에 노이즈를 추가하는 방식으로 쉽게 구현할 수 있습니다. PyTorch의 `Opacus`나 TensorFlow의 `tensorflow_privacy`와 같은 라이브러리를 Flower 클라이언트 로직에 통합하여 차분 프라이버시를 적용하는 것이 일반적인 접근 방식입니다.
- **XGBoost와의 관계**: 연합학습 환경의 XGBoost에도 적용 가능합니다. 예를 들어, SecureBoost 방식에서 각 클라이언트가 자신의 그래디언트 통계량을 서버에 보내기 전에 노이즈를 추가하거나, 최종적으로 만들어진 트리의 각 리프 노드(leaf node)의 예측값에 노이즈를 추가하여 개별 데이터의 영향을 숨길 수 있습니다.

#### 3. 그래디언트 기반 연합 부스팅 (Gradient-based Federated Boosting)

- **개념**: 이종(heterogeneous) 데이터 환경에서 XGBoost와 같은 트리 기반 부스팅 모델을 연합학습 시키기 위해 특별히 설계된 알고리즘입니다. FedAvg처럼 완성된 모델을 교환하는 대신, **하나의 글로벌 트리를 협력하여 함께 만들어가는** 방식입니다. `SecureBoost`가 대표적인 구현체이며, `FATE`는 이를 포함한 다양한 연합학습 알고리즘을 제공하는 오픈소스 프레임워크입니다.
- **작동 방식**:
    1.  서버(또는 Active Party)가 현재까지 학습된 모델을 기반으로 그래디언트와 헤시안을 계산합니다.
    2.  이 정보를 암호화하여 모든 클라이언트(Passive Party)에게 전달합니다.
    3.  각 클라이언트는 자신의 로컬 데이터와 암호화된 정보를 이용해, 자신의 피처 중에서 최적의 분기점(split point) 후보들을 찾고 관련 통계량을 계산하여 서버에 다시 보냅니다. 이 과정에서 데이터 자체는 절대 유출되지 않습니다.
    4.  서버는 모든 클라이언트로부터 받은 정보를 취합하여 이번 트리의 최적 분기점을 결정하고, 트리를 한 단계 성장시킵니다.
    5.  이 과정을 반복하여 하나의 트리를 완성하고, 다시 다음 트리를 만드는 방식으로 전체 모델을 학습시킵니다.
- **Flower와의 관계**: 표준 Flower의 `FedAvg` 전략과는 통신 패턴이 완전히 다릅니다. FedAvg는 `fit` -> `aggregate`의 단순한 구조이지만, SecureBoost는 트리 생성을 위해 서버와 클라이언트 간의 여러 차례의 상호작용이 필요합니다. 따라서 Flower의 기본 구조만으로는 SecureBoost를 구현하기 매우 어렵고, 별도의 복잡한 통신 로직과 `Strategy` 구현이 필요합니다.
- **XGBoost와의 관계**: **이것이 바로 XGBoost 연합학습의 '정석'입니다.** 데이터 분포가 달라 클라이언트마다 모델 구조가 달라지는 근본적인 문제를 완벽하게 해결합니다. 모든 참여자가 각자의 데이터 특성을 반영하여 단일의 일관된 글로벌 모델을 함께 만들어가므로, 높은 성능을 달성할 수 있습니다.

#### 4. 온라인 피드백 + 그래프 신경망 (Online Feedback + GNN)

- **개념**: 정적인 데이터셋으로 한 번만 학습하는 것을 넘어, 시스템을 지속적으로 진화시키는 동적 아키텍처입니다.
    - **온라인 피드백 (Online Feedback)**: 모델이 운영 환경에서 예측한 결과(예: '이 거래는 사기다')와 실제 정답('실제로 사기였음')을 지속적으로 수집하여 모델을 업데이트하는 방식입니다. 이를 통해 최신 사기 패턴에 실시간으로 적응할 수 있습니다.
    - **그래프 신경망 (GNN, Graph Neural Networks)**: 개별 거래를 독립적으로 보지 않고, '사용자', '계좌', '기기' 등을 노드(Node)로, '거래'를 엣지(Edge)로 연결한 거대한 '금융 관계망' 그래프를 분석하는 기술입니다. GNN은 개별 사용자의 특징뿐만 아니라, 연결 관계(예: 여러 계좌가 동일한 기기에서 접속)에서 나타나는 복잡한 패턴을 학습하여, 개별적으로는 탐지가 어려운 조직적인 사기 행각(Fraud Ring)을 식별하는 데 매우 강력합니다.
- **Flower/XGBoost와의 관계**: 이는 특정 알고리즘이라기보다는 시스템 아키텍처에 가깝습니다.
    - Flower는 온라인 피드백 루프를 구현하는 데 사용될 수 있습니다. 예를 들어, 하루 동안 쌓인 새로운 거래 데이터와 피드백을 이용해 매일 밤 Flower를 통해 연합학습을 수행하도록 파이프라인을 구축할 수 있습니다.
    - 학습되는 모델 자체를 GNN으로 사용할 수 있습니다. 이 경우, 각 은행은 자신들의 고객과 관련된 부분 그래프(subgraph)를 가지고 있으며, Flower를 통해 **'연합 그래프 신경망'**을 학습시킬 수 있습니다. 또는, GNN을 통해 사용자나 거래의 위험도를 나타내는 새로운 피처(feature)를 생성하고, 이 피처들을 기존 데이터와 합쳐 **XGBoost 모델의 입력값**으로 사용할 수도 있습니다. 이 XGBoost 모델을 SecureBoost 방식으로 연합학습 시킨다면, 관계형 데이터의 강점과 부스팅 모델의 성능을 모두 취할 수 있습니다. 