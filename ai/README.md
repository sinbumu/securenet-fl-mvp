# SecureNet-FL AI 모델 개발 히스토리

이 문서는 연합 학습(Federated Learning) 기반 사기 탐지 AI 모델을 개발하는 과정에서 발생했던 주요 이슈와 해결 과정을 기록합니다.

## 1. 프로젝트 목표

- 여러 은행에 분산된 데이터를 개인정보 유출 없이 안전하게 학습하여, 금융 사기를 탐지하는 고성능 AI 모델을 구축한다.
- **기술 스택**: `Flower` (연합 학습 프레임워크), `XGBoost` (머신러닝 모델)
- **시나리오**: 3개의 은행(클라이언트)이 각자의 데이터를 로컬에서 학습하고, 중앙 서버는 이 학습 결과를 종합하여 글로벌 모델을 개선한다.

## 2. 초기 접근 및 첫 번째 난관

### 초기 설계
- Flower의 표준적인 `FedAvg` (Federated Averaging) 전략을 사용하여 각 클라이언트의 XGBoost 모델 업데이트를 서버에서 평균 내는 방식으로 구현을 시도했습니다.

### 발생 문제: 모델 파라미터 불일치
- 각 클라이언트는 서로 다른 데이터로 학습하므로, XGBoost의 트리 구조가 서로 다르게 생성되었습니다.
- 이로 인해 모델 파라미터의 배열 형태(shape)가 클라이언트마다 달라져, 서버에서 `np.add`를 통해 이를 집계하려 할 때 `ValueError: operands could not be broadcast together with shapes (...)` 오류가 발생하며 학습이 실패했습니다.

## 3. 1차 해결: 집계 전략 변경

### 해결 방안
- `FedAvg`의 '평균' 방식이 트리 기반 모델인 XGBoost에 적합하지 않다고 판단했습니다.
- 서버의 집계 전략을 수정하여, 매 라운드마다 **첫 번째 클라이언트로부터 받은 모델을 다른 모든 클라이언트에게 그대로 전파(broadcast)**하는 '순환(Cyclic)' 방식으로 변경했습니다.
- 이를 통해 모든 클라이언트가 동일한 모델 구조 위에서 순차적으로 학습을 이어가게 하여 파라미터 불일치 문제를 해결하고, 기본적인 연합 학습 플로우를 완성했습니다.

## 4. 두 번째 난관: '껍데기 뿐인' 모델

### 문제 발견: 99.9% 정확도의 함정
- 기본 학습이 완료된 모델의 성능을 평가용 데이터셋으로 검증했습니다.
- **정확도(Accuracy)는 99.87%**로 매우 높게 측정되었지만, **실제 사기(Fraud) 거래는 단 한 건도 탐지하지 못하는 심각한 문제**를 발견했습니다. (재현율 Recall = 0)

### 원인 분석: 극심한 클래스 불균형 (Class Imbalance)
- 전체 거래 데이터 중 사기 거래는 0.13%에 불과했습니다.
- 모델이 어려운 소수 클래스(사기)를 학습하기보다는, **모든 거래를 '정상'이라고 예측하는 쉬운 길을 선택**하여 높은 정확도를 얻는 함정에 빠진 것입니다.

## 5. 최종 해결 및 모델 완성

### 해결 방안: `scale_pos_weight` 파라미터 적용
- XGBoost에서 클래스 불균형 문제를 해결하기 위해 제공하는 `scale_pos_weight` 파라미터를 도입했습니다.
- (정상 거래 수 / 사기 거래 수) 비율인 약 `773`을 가중치로 부여하여, 모델이 사기 거래를 하나 틀렸을 때 받는 페널티를 대폭 상승시켰습니다.
- 이를 통해 모델이 더 이상 소수 클래스를 무시하지 않고 적극적으로 학습하도록 유도했습니다.

### 최종 결과
- `scale_pos_weight`를 적용하여 모델을 재학습하고 다시 평가했습니다.
- **정확도(Accuracy) 99.96%**를 유지하면서, 이전에는 0%였던 **사기 탐지 재현율(Fraud Recall)이 99.8%**로 극적으로 향상되었습니다.
- 최종적으로 **실질적인 사기 탐지 능력을 갖춘 고성능 AI 모델**을 완성할 수 있었습니다. 