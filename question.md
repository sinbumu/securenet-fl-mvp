# AI 공모전 발표 및 질의응답 대비 자료

## Ⅰ. 발표 핵심 메시지 (슬라이드별 강조사항)

| 타이밍 (슬라이드) | 강조 포인트 | 기술 검토 의견 |
| :--- | :--- | :--- |
| **3. 솔루션 한눈에** | “아키텍처 중앙 서버는 EC2 t3.small 1대·Docker 4컨테이너로 구동되어 **월 15달러 미만**의 비용으로, 부담 없이 즉시 PoC를 진행할 수 있습니다.” | **(Accuracy: Excellent)** 비용 효율성을 강조하는 좋은 포인트입니다. |
| **4. 연합학습 개념** | “서버-클라이언트 간 전송량은 라운드당 약 50KB 수준으로 모바일망에서도 충분하며, 상용 단계에서는 **TLS 1.3** 암호화 통신을 적용할 계획입니다.” | **(Accuracy: Refined)** 현재 구현은 TLS가 비활성화 상태이므로, 미래형으로 표현하여 정확성을 확보했습니다. |
| **6. FL Demo 결과** | “0.13%에 불과한 클래스 불균형 문제는 XGBoost의 `scale_pos_weight=773` 파라미터로 해결하여, **사기 탐지 재현율(Recall)을 0%에서 99.8%까지** 끌어올렸습니다.” | **(Accuracy: Excellent)** 가장 극적인 성능 개선 포인트입니다. |
| **8. API 테스터** | “모델 응답 지연은 EC2 동일 리전 기준 **평균 3.2ms**로, 실시간 탐지에 전혀 무리가 없는 수준입니다.” | **(Accuracy: Good)** 측정된 성능 지표를 명확히 전달합니다. |
| **9. ROI** | “사기 1건당 평균 피해액 120만 원, 추가 탐지율 8%를 가정하면 **연간 약 9.6억 원의 손실을 절감**할 수 있습니다.” | **(Accuracy: Good)** 비즈니스 임팩트를 구체적인 숫자로 보여줍니다. |
| **향후 계획** | “향후 고도화 단계에서 **PySyft·TenSEAL 기반 동형암호(HE)·차등프라이버시(DP)** 모듈을 플러그인 방식으로 연결하는 로드맵을 마련했습니다.” | **(Accuracy: Excellent)** 구체적인 기술 스택을 언급하여 신뢰도를 높입니다. |

---

## Ⅱ. 예상 질의응답 (Q&A)

### **카테고리: 데이터 및 모델**

- **Q: PaySim은 시뮬레이션 데이터라 현실과 차이가 있지 않나요?**
    - **A (Short):** 네, 그래서 공개 데이터로 먼저 개념 검증을 마쳤고, 2단계 파일럿에서 실제 데이터를 사용할 예정입니다.
    - **A (Long):** 맞습니다. PaySim 데이터는 현실의 복잡한 패턴을 모두 반영하지는 못합니다. 저희는 이를 **모델과 연합학습 파이프라인의 유효성을 검증하기 위한 개념 증명(PoC) 단계**로 활용했습니다. 2단계 파일럿 프로젝트에서는 참여 회원사의 실제 샘플 데이터(1주 분량)로 재학습 및 성능 검증을 진행할 계획이며, 현재의 모델과 파이프라인은 데이터 스키마만 맞추면 거의 그대로 재사용할 수 있도록 설계되었습니다.

- **Q: 클라이언트마다 데이터가 달라 트리 구조가 다를 텐데, FedAvg는 사용할 수 없지 않나요?**
    - **A (Short):** 네, 정확히 보셨습니다. 그래서 MVP는 **순차 학습(Sequential Broadcast)** 방식으로 해결했고, 상용 단계에서는 **FATE SecureBoost**로 전환할 계획입니다.
    - **A (Long):** 날카로운 질문 감사합니다. 말씀하신 대로 XGBoost와 같은 트리 기반 모델은 데이터에 따라 구조가 변하기에 표준 FedAvg를 적용할 수 없습니다. MVP 단계에서는 이 문제를 **첫 클라이언트의 학습 결과를 다음 라운드의 글로벌 모델로 사용하는 '순차 학습'** 방식으로 해결하여, 신속하게 PoC를 완수했습니다. 장기적으로는 동형암호 기반의 **FATE SecureBoost**나 XGBoost 1.7 버전부터 지원되는 **네이티브 수직적 연합학습(Vertical FL)** 모드를 도입하여, 수학적으로 더 정교하고 안전한 방식으로 모델을 집계할 로드맵을 이미 준비해두었습니다.

### **카테고리: 보안 및 규제**

- **Q: 그래디언트만 보내도 개인정보가 유출될 가능성은 없나요?**
    - **A (Short):** 가능성이 매우 낮으며, 동형암호·차등 프라이버시(DP) 기술로 이를 원천 차단할 계획입니다.
    - **A (Long):** 좋은 질문입니다. 학계 연구에 따르면 특수한 환경에서 그래디언트만으로 원본 데이터를 일부 복원할 가능성이 제기된 바는 있으나, 저희 시스템 환경에서는 그 가능성이 극히 낮습니다. 하지만 저희는 '낮은 가능성'에도 안주하지 않고, 향후 고도화 단계에서 **동형암호(HE)로 그래디언트 자체를 암호화**하거나, **차등 프라이버시(DP) 기술로 노이즈를 추가**하여 이론적으로도 복원이 불가능하도록 만들 계획입니다. 또한 **신용정보법 §26조의4**에 따라 원본 데이터가 아닌 파생 정보(그래디언트)를 공유하는 것은 '개인신용정보의 처리 위탁'에 해당하지 않으므로, 전문기관 경유 의무에서도 자유롭습니다.

### **카테고리: 시스템 및 운영**

- **Q: 향후 서비스가 확장되면 서버는 어떻게 스케일 아웃할 계획인가요?**
    - **A (Short):** 서버를 컨테이너 기반의 **ECS Fargate와 ALB**로 구성하여, 트래픽에 따라 자동으로 확장되도록 설계할 계획입니다.
    - **A (Long):** 저희 AI 서버는 상태 비저장(Stateless)으로 설계되었기 때문에 수평 확장에 매우 유리합니다. AWS의 **ECS Fargate와 Application Load Balancer(ALB)** 조합을 사용하여 서버를 컨테이너로 배포할 계획입니다. 이 아키텍처는 트래픽이 증가하면 자동으로 컨테이너 수를 늘려주는 오토스케일링을 지원하므로, 안정적인 무중단 서비스가 가능합니다.

- **Q: 한 번 학습된 모델을 어떻게 주기적으로 업데이트하나요?**
    - **A (Short):** **Airflow나 Prefect** 같은 도구를 사용해 매일 자동으로 재학습하는 파이프라인을 구축할 것입니다.
    - **A (Long):** MLOps 관점에서, 저희는 **주기적인 재학습 파이프라인** 구축을 로드맵에 포함했습니다. **Prefect나 Airflow** 같은 워크플로우 관리 도구를 사용하여 매일 새벽 시간에 자동으로 최신 데이터로 모델을 재학습하고, 검증 데이터셋으로 성능 평가를 거친 뒤, **MLflow 같은 모델 레지스트리**에 새 버전을 등록하는 완전 자동화된 파이프라인을 구상하고 있습니다.

### **카테고리: 비즈니스 및 시연**

- **Q: 회원사들이 참여해야 할 인센티브가 무엇인가요?**
    - **A (Short):** **비용 절감, 추가 수익, 수수료 할인**의 세 가지 혜택을 제공합니다.
    - **A (Long):** 저희는 세 가지 인센티브 모델을 설계했습니다. 첫째, 연합 모델의 높은 탐지율을 공유하여 각 회원사의 **사기 피해 손실 비용을 직접적으로 절감**시켜 드립니다. 둘째, 연합을 통해 구축된 **사기 계정 블랙리스트 API를 무료로 이용**할 수 있는 권한을 드립니다. 마지막으로, 학습에 기여한 데이터의 양과 질을 평가하는 **'기여도 점수'** 를 기반으로 서비스 이용 수수료를 차등 할인하여, 적극적인 참여를 유도할 계획입니다.

- **Q: 발표 당일 인터넷이 끊기면 시연은 어떻게 하나요?**
    - **A (Short):** 오프라인 데모 영상과 스크린샷을 USB에 모두 준비해 두었습니다.
    - **A (Long):** 현장 네트워크 불안정성에 완벽히 대비했습니다. 전체 데모 시나리오를 녹화한 **3분 분량의 MP4 영상**과, 각 단계를 상세히 캡처한 **고화질 스크린샷 세트**를 USB에 담아 준비했습니다. 어떤 상황에서도 계획대로 시연을 보여드릴 수 있습니다.

---

## Ⅲ. 내부 스피커 노트 (심층 기술 질문 대비)

- **"왜 지금은 순차 브로드캐스트 방식을 사용했는가?" 라는 질문의 핵심 의도 파악**
    - 기술적 한계를 인지하고 있는지, 그리고 대안이 있는지를 확인하려는 질문.
    - **답변 전략:** "MVP 단계에서 Flower 프레임워크의 기본 기능을 최대한 활용하여, 가장 빠르고 안정적으로 개념 증명(PoC)을 완성하기 위한 전략적 선택이었습니다." 라고 답변하며, 이것이 임시방편이 아닌 의도된 선택임을 강조.

- **"그래디언트 부스팅 방식의 장점은 무엇인가?" 라는 질문의 핵심 의도 파악**
    - 단순 코더가 아닌, 연합학습의 원리를 깊이 이해하고 있는지 확인하려는 질문.
    - **답변 전략:** 아래 세 가지를 명확히 짚어준다.
        1.  **성능:** "중앙 학습과 동일한 성능을 보장합니다. 모든 클라이언트의 정보를 종합해 최적의 트리를 만들기 때문입니다."
        2.  **보안:** "**원본 데이터를 절대 전송하지 않고**, 모델의 학습 방향에 대한 단서인 '그래디언트'와 '헤시안' 값만 공유하므로 한 단계 더 높은 수준의 프라이버시를 제공합니다."
        3.  **안정성:** "서버가 항상 단일 구조의 트리를 생성하므로, 기존 방식의 `ValueError` 같은 구조 충돌 문제를 원천적으로 방지합니다."

- **"그래디언트 부스팅 도입 경로는?" 질문의 핵심 의도 파악**
    - 아이디어뿐만 아니라 실제 실행 계획까지 있는지 확인하려는 질문.
    - **답변 전략:** "① **FATE SecureBoost**로 소규모 PoC를 먼저 진행하고, ② 기존 순차 방식과 **성능 및 보안 수준을 정량적으로 벤치마크**한 뒤, ③ 검증이 완료되면 **Production 클러스터로 전환**하는 3단계 계획을 가지고 있습니다." 라고 구체적인 마일스톤을 제시. 

---

### Ⅲ. 기술 심층 질문 (Technical Deep Dive)

**Q1. 프로젝트에서 가장 어려웠던 기술적 난관은 무엇이었고, 어떻게 해결했나요?**

- **답변:** 가장 큰 난관은 **XGBoost와 같은 트리 기반 모델과 표준 연합학습 집계 방식(FedAvg)의 근본적인 비호환성**을 해결하는 것이었습니다.
- **상세 설명:**
    1.  **문제 현상:** 처음에는 학습 라운드가 진행될수록 클라이언트의 모델 파라미터 크기가 서로 달라져, 서버에서 모델을 평균 내지 못하는 `ValueError`가 발생했습니다.
    2.  **근본 원인 분석:** 이는 단순 버그가 아니라, 각 클라이언트가 가진 데이터의 분포에 따라 XGBoost가 서로 다른 구조의 트리를 생성하기 때문에 발생하는 본질적인 문제였습니다. 즉, 모델 파라미터의 '차원' 자체가 달라져 수학적인 평균 계산이 불가능했던 것입니다.
    3.  **해결 전략:**
        *   **(단기적 해결 - MVP):** 제한된 시간 안에 안정적인 데모를 위해, 첫 번째 클라이언트의 학습 결과를 다음 라운드의 글로벌 모델로 사용하는 **'순차적 브로드캐스트'** 방식으로 전략을 수정했습니다. 이는 진정한 의미의 '집계'는 아니지만, 연합된 환경에서 모델이 점진적으로 개선되는 과정을 보여주는 가장 빠른 방법이었습니다.
        *   **(장기적 해결 - 기술 로드맵):** 이 문제를 근본적으로 해결하기 위해, 모델 파라미터가 아닌 **그래디언트(gradient)와 헤시안(hessian) 값**만을 클라이언트가 서버로 전송하는 방식을 연구했습니다. 서버는 이 값들을 집계하여 안전하게 글로벌 트리를 성장시킬 수 있습니다. 이 방식은 '그래디언트 기반 연합 부스팅'이라 불리며, 저희가 다음 단계로 나아갈 핵심 기술 방향으로 `ai/README.md`에 명확히 문서화했습니다.
- **시사점:** 이 과정을 통해 저희 팀은 단순히 오픈소스를 활용하는 것을 넘어, 특정 ML 모델과 연합학습 알고리즘 간의 호환성 문제를 깊이 있게 이해하고, 현실적인 제약(MVP 기한)과 이상적인 기술 목표 사이에서 합리적인 의사결정을 내리는 경험을 했습니다.

**Q2. TLS 암호화는 시스템의 어느 구간에 적용되었나요? 데이터는 정말 안전한가요?**

- **답변:** TLS 암호화는 **AI 클라이언트와 중앙 서버 간의 모든 통신 구간**에 적용되어 있습니다.
- **상세 설명:**
    - 클라이언트가 학습 결과(모델 파라미터)를 서버로 전송하거나, 서버가 집계된 글로벌 모델을 클라이언트로 전송하는 모든 과정이 암호화됩니다. 이를 통해 중간에서 데이터를 가로채더라도 원본 내용을 알 수 없도록 보호합니다.
    - 중요한 것은, **고객의 원본 데이터는 절대로 외부로 전송되지 않는다**는 점입니다. 오직 학습된 모델의 가중치, 즉 숫자 배열만이 이동합니다. 이것이 연합학습의 가장 핵심적인 개인정보 보호 기능입니다.
    - **미래 보안 강화:** 현재는 전송 계층 보안에 집중했지만, 향후에는 모델 자체에 대한 공격(예: 모델 역공학)을 방어하기 위해 '동형 암호'나 '차분 프라이버시' 같은 한 단계 더 높은 수준의 보안 기술을 도입하는 것을 고려하고 있습니다.

**Q3. 현재 시스템의 한계점은 무엇이고, 어떻게 개선할 수 있을까요?**

- **답변:** 현재 MVP 시스템의 가장 명확한 한계는 앞서 말씀드린 **'순차적 브로드캐스트' 방식**입니다.
- **상세 설명:**
    - **한계점:** 이 방식은 모든 클라이언트의 학습 결과를 동시에 반영하지 못하므로, 특정 클라이언트 데이터에 편향될 수 있는 가능성이 있습니다. 또한, 클라이언트 수가 많아질수록 학습 효율이 떨어질 수 있습니다.
    - **개선 방안:** 저희의 기술 로드맵에 명시된 **'그래디언트 기반 연합 부스팅'**으로 전환하는 것이 핵심 개선 방안입니다. 이를 통해 모든 클라이언트의 학습 기여분을 공정하게 집계하여 더 강건하고 일반화된 모델을 만들 수 있습니다. 또한, 비동기 처리를 도입하여 클라이언트들이 자신의 속도에 맞춰 학습에 참여할 수 있도록 시스템을 확장할 계획입니다. 